services:
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.34.0
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
      CLUSTER_HOSTNAME: 'node1'
      OLLAMA_API_ENDPOINT: 'http://ollama:11434'
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:0.12.9
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  weaviate_data:
  ollama_data:


# services:
#   weaviate:
#     command:
#       - --host
#       - 0.0.0.0
#       - --port
#       - '8080'
#       - --scheme
#       - http
#     image: cr.weaviate.io/semitechnologies/weaviate:1.34.0
#     ports:
#       - 8080:8080
#       - 50051:50051
#     volumes:
#       - weaviate_data:/var/lib/weaviate
#     restart: on-failure:0
#     environment:
#       QUERY_DEFAULTS_LIMIT: 25
#       AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
#       PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
#       DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
#       ENABLE_MODULES: 'text2vec-transformers'
#       TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'

#   t2v-transformers:
#     image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
#     container_name: weaviate-transformers
#     environment:
#       ENABLE_CUDA: '0'

# volumes:
#   weaviate_data: